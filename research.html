<!DOCTYPE HTML>
<!--
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Research interest and history</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
					
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Education</a></li>
							<li class="active"><a href="research.html">Research</a></li>
							<li><a href="Industry.html">Industry</a></li>
                            <li><a href="Competitions.html">Competitions</a></li>
                            <li><a href="hobbies.html">Activities</a></li>
                            <li><a href="contact.html">Contact</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.instagram.com/huangyuan07/?igshid=MDM4ZDc5MmU%3D" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="https://twitter.com/Huangyu58589918" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://github.com/Hither1/" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
				<div id="main">
					<div class="image main"><img src="images/carla.jpg" alt="" /></div>

					<h2>Ongoing Projects</h2>
					<section class="post">
						<header class="major">
							<h3>Multi-Agent Model-Based Planning with Diffusion Policy</h3>
							
									<!-- <img src="images/mckinsey.png" width="15%" height="15%" alt="" style="float:left; padding-top:20px; padding-left:15px"/> -->
							
							<h3>Towards Scalable and Reliable One-shot Skeleton-based Action Recognition</h3>
								<!-- <h5></h5><p><a href="">link</a></p> -->
									 
						</header>
						<p></p>
					</section>
					
				</div>
				
				<div id="main">
					<div class="image main"><img src="images/carla.jpg" alt="" /></div>

					<h2>Publications and preprints</h2>
					<section class="post">
						<header class="major">
							<h3>Model-Based Planning with Stochastic Trajectory Prediction Models for Urban Driving</h3>
								<h5></h5>
									  <a href="https://avillaflor.github.io/">Adam Villaflor</a>, <a href="https://byang.org/">Brian Yang</a>, Huangyuan Su, John Dolan <a href="https://www.cs.cmu.edu/~schneide/">Jeff Scheneider</a> (Supervisor)



							
							<h3>Representations Overlaps in Deep Reinforcement Learning</h3></p>
									  <h5>CVPR 2023</h5><a href="https://openaccess.thecvf.com/content/CVPR2023/html/He_Frustratingly_Easy_Regularization_on_Representation_Can_Boost_Deep_Reinforcement_Learning_CVPR_2023_paper.html">link</a>
										  <h5>Qiang He, Huangyuan Su, Jieyu Zhang, Yu Liu, Xinwen Hou</h5><p></p>





							<h3>Talk-to-Diffusion: A Language-Controllable Diffusion Policy for Autonomous Driving</h3>
										  <h5>Brian Yang, Nikolaos Gkanatsios, Huangyuan Su, Ayush Jain, Jeff Schneider, Katerina Fragkiadaki </h5><p><a href=""></a></p>
											    <a href=""></a>  




							<h3>Reinventing Policy Iteration under Time Inconsistency</h3>
							
							<h5>Paper: <a href="https://openreview.net/forum?id=bN2vWLTh0P">link</a>      Code: <a href="https://github.com/Hither1/Time-Inconsistency-RL">link</a></h5>
								<h5>Huangyuan Su, Nixie Lesmana, <a href="https://personal.ntu.edu.sg/cspun/">Pun Chi Seng</a> (Supervisor)</h5><p></p>
							<h5>TMLR 2022</h5>
							Reinforcement Learning (RL) is a sub-domain of machine learning that is concerned with how an algorithmic agent can take actions in a certain environment so that it can accumulate reward. 
                                    Deep reinforcement learning (DRL) is the marriage between deep learning and reinforcement learning. In recent years, DRL has achieved glorious success in various fields. 
                                    The most well-known example is probably the victory of AlphaGo against the top human Go masters. But beyond games, DRL certainly has much more applications, which include but are not limited to resources management in computer clusters, robotics and web system configuration.

                                    Temporal Credit Assignment (TCA) problem is the problem of determining the actions that lead to a certain outcome. This is of ultimate importance to the study of DRL as most RL algorithms or agents are essentially attempting to solve the TCA problem.

							

							
						</header>
						<p></p>
					</section>
					
				</div>
				
					

				<!-- Footer -->
					<footer id="footer">
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>